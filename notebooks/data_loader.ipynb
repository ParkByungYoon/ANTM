{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFile\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, Compose\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from transformers import pipeline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.timefeatures import time_features\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "\n",
    "class ZeroShotDataset():\n",
    "    def __init__(self, sales_total_len, seq_len, output_dim, data_df, img_root,\n",
    "                 cat_trend, fab_trend, col_trend, trend_len,\n",
    "                 scaler, no_scaling, meta_df, qcut_df, opt_lambda=None, train=True):\n",
    "        self.sales_total_len = sales_total_len\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.data_range = self.sales_total_len - self.seq_len - self.output_dim + 1\n",
    "\n",
    "        self.data_df = data_df\n",
    "        self.img_root = img_root\n",
    "        self.cat_trend = cat_trend\n",
    "        self.fab_trend = fab_trend\n",
    "        self.col_trend = col_trend\n",
    "\n",
    "        self.img_df = meta_df.loc[:,meta_df.columns.str.startswith('img')]\n",
    "        self.text_df = meta_df.loc[:,meta_df.columns.str.startswith('text')]\n",
    "        self.meta_df = meta_df.iloc[:,3:26]\n",
    "\n",
    "        # self.text_des = text_des\n",
    "        # self.text_embedder = pipeline('feature-extraction', model=text_embedder)\n",
    "        self.trend_len = trend_len\n",
    "        self.scaler = StandardScaler() if scaler == \"standard\" else MinMaxScaler()\n",
    "        self.no_scaling = no_scaling\n",
    "\n",
    "        \n",
    "        self.qcut_df = qcut_df\n",
    "        self.qcut_label_mean = qcut_df.groupby('qcut_label')['sales_mean'].mean().values\n",
    "        self.qcut_label_median = qcut_df.groupby('qcut_label')['sales_mean'].median().values\n",
    "\n",
    "        if opt_lambda == None:\n",
    "            _, self.opt_lambda = boxcox(qcut_df.loc[self.data_df.index, 'sales_mean'])\n",
    "        else:\n",
    "            self.opt_lambda = opt_lambda\n",
    "\n",
    "        self.train = train\n",
    "        self.past_trend_len = trend_len - sales_total_len\n",
    "        self.col_imputation = self.color_imputation()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_df.iloc[idx, :]\n",
    "\n",
    "    def color_imputation(self):\n",
    "        col_trend_df = pd.DataFrame(self.col_trend)\n",
    "        normal_item_df = col_trend_df.drop(columns=[item  for item in col_trend_df.columns if col_trend_df[item][0] == \"multi_color\"])\n",
    "        col_imputation = np.mean([np.mean(normal_item_df[item]) for item in normal_item_df.columns])\n",
    "        return col_imputation\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        data = self.data_df.reset_index(drop=True)\n",
    "\n",
    "        # Get the Gtrends time series associated with each product\n",
    "        # Read the images (extracted image features) as well\n",
    "        sales, release_dates, ntrends, image_features, text_features, sales_stamps, scalers, real_value_sales, item_numbers_idx = [], [], [], [], [], [], [], [], []\n",
    "        metas = []\n",
    "        qcut_labels = []\n",
    "        target_regs = []\n",
    "\n",
    "        img_transforms = Compose([Resize((256, 256)), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "        for (idx, row) in tqdm(data.iterrows(), total=len(data), ascii=True):\n",
    "        # for (idx, row) in tqdm(data[:20].iterrows(), total=len(data[:20]), ascii=True):\n",
    "            item_numbers_idx.append(idx)\n",
    "\n",
    "            idx = self.data_df.iloc[idx]._name\n",
    "\n",
    "            meta = self.meta_df.loc[idx].values\n",
    "            metas.append(meta)\n",
    "\n",
    "            qcut = int(self.qcut_df.loc[idx]['qcut_label'])\n",
    "            qcut_labels.append(qcut)\n",
    "\n",
    "            reg = boxcox(self.qcut_df.loc[idx]['sales_mean'], self.opt_lambda)\n",
    "            target_regs.append(reg)\n",
    "\n",
    "            sales_stamp = []\n",
    "\n",
    "            row.index = pd.to_datetime(row.index)\n",
    "\n",
    "            release_date = row.dropna().sort_index().index[0]\n",
    "            release_dates.append([release_date.year, release_date.month, release_date.day])\n",
    "\n",
    "            row = row[release_date:release_date + relativedelta(weeks=self.output_dim-1)].resample('7d').sum().fillna(0)\n",
    "\n",
    "            time_feature_range = pd.date_range(release_date - relativedelta(weeks=52), release_date + relativedelta(weeks=self.output_dim-1), freq='7d')\n",
    "            sales_stamp.append(time_features(time_feature_range, freq='w')[0].tolist())\n",
    "            sales_stamp.append(time_features(time_feature_range, freq='m')[0].tolist())\n",
    "            sales_stamp.append(time_features(time_feature_range, freq='y')[0].tolist())\n",
    "\n",
    "            real_value_sale = torch.FloatTensor(np.array(row))\n",
    "            real_value_sales.append(real_value_sale)\n",
    "\n",
    "            # sale = np.array(row) / 290\n",
    "            sale = self.scaler.fit_transform(np.array(row).reshape(-1, 1)).flatten()\n",
    "\n",
    "            if self.no_scaling:\n",
    "                sale = np.array(row)\n",
    "\n",
    "            sale = torch.FloatTensor(sale)\n",
    "\n",
    "            sales.append(sale)\n",
    "\n",
    "\n",
    "            scalers.append([self.scaler.mean_, self.scaler.scale_]) if isinstance(self.scaler, StandardScaler) else scalers.append([self.scaler.data_min_, self.scaler.data_range_])\n",
    "\n",
    "            if idx in self.cat_trend.keys():\n",
    "                cat_ntrend = np.array(self.cat_trend[idx]).reshape(-1,1)\n",
    "                if cat_ntrend.shape[0] != 64:\n",
    "                    cat_ntrend = torch.zeros(self.trend_len, 1)\n",
    "\n",
    "                fab_ntrend = np.array(self.fab_trend[idx]).reshape(-1,1)\n",
    "                if fab_ntrend.shape[0] != 64:\n",
    "                    fab_ntrend = torch.zeros(self.trend_len, 1)\n",
    "\n",
    "                col_ntrend = np.array(self.col_trend[idx]).reshape(-1,1)\n",
    "                if self.col_trend[idx] == \"multi_color\":\n",
    "                    col_ntrend = torch.zeros(self.trend_len,1)\n",
    "                else:\n",
    "                    col_scaler = StandardScaler().fit(col_ntrend[:self.past_trend_len])\n",
    "                    col_ntrend = col_scaler.transform(col_ntrend)\n",
    "                if col_ntrend.shape[0] != 64:\n",
    "                    col_ntrend = torch.zeros(self.trend_len, 1)\n",
    "\n",
    "                cat_scaler = StandardScaler().fit(cat_ntrend[:self.past_trend_len])\n",
    "                cat_ntrend = cat_scaler.transform(cat_ntrend)\n",
    "                fab_scaler = StandardScaler().fit(fab_ntrend[:self.past_trend_len])\n",
    "                fab_ntrend = fab_scaler.transform(fab_ntrend)\n",
    "            else:\n",
    "                col_ntrend = torch.zeros(self.trend_len, 1)\n",
    "                cat_ntrend = torch.zeros(self.trend_len, 1)\n",
    "                fab_ntrend = torch.zeros(self.trend_len, 1)\n",
    "\n",
    "\n",
    "            \n",
    "            multitrends = torch.stack([torch.FloatTensor(cat_ntrend), torch.FloatTensor(fab_ntrend), torch.FloatTensor(col_ntrend)]).squeeze()    \n",
    "            img = Image.open(os.path.join(self.img_root, idx + '.png')).convert('RGB')\n",
    "            # textual_description = list(self.text_des.loc[idx])\n",
    "            # word_embeddings = self.text_embedder(textual_description)\n",
    "\n",
    "            # BERT gives us embeddings for [CLS] ..  [EOS], which is why we only average the embeddings in the range [1:-1]\n",
    "            # We're not fine tuning BERT and we don't want the noise coming from [CLS] or [EOS]\n",
    "            word_embeddings = torch.FloatTensor(self.text_df.loc[idx].values)\n",
    "            text_features.append(word_embeddings)\n",
    "\n",
    "            # Append them to the lists\n",
    "            ntrends.append(multitrends)\n",
    "            # img = img_transforms(self.img_df.loc[idx].values)\n",
    "            img = img_transforms(img)\n",
    "            image_features.append(img)\n",
    "\n",
    "            sales_stamp = torch.FloatTensor(sales_stamp)\n",
    "            sales_stamps.append(sales_stamp)\n",
    "\n",
    "        # Create tensors for each part of the input/output\n",
    "        item_sales = torch.stack(sales, dim=0)\n",
    "        temporal_features = torch.stack(sales_stamps, dim=0)\n",
    "        ntrends = torch.stack(ntrends, dim=0)\n",
    "        images = torch.stack(image_features, dim=0)\n",
    "        texts = torch.stack(text_features, dim=0)\n",
    "        scalers = torch.FloatTensor(np.array(scalers)).view(-1, 2)\n",
    "\n",
    "        real_value_sales = torch.stack(real_value_sales, dim=0)\n",
    "\n",
    "        release_dates = torch.tensor(release_dates)\n",
    "\n",
    "        item_numbers_idx = torch.tensor(item_numbers_idx)\n",
    "\n",
    "        meta_data = torch.FloatTensor(metas)\n",
    "        qcut_labels = torch.LongTensor(qcut_labels)\n",
    "\n",
    "        target_reg = torch.FloatTensor(target_regs)\n",
    "\n",
    "        \n",
    "        return TensorDataset(item_sales, temporal_features, ntrends, images, texts, scalers,\n",
    "                             real_value_sales, release_dates, item_numbers_idx, meta_data, \n",
    "                             qcut_labels, target_reg)\n",
    "\n",
    "    def get_loader(self, batch_size, train=True):\n",
    "        print('Starting dataset creation process...')\n",
    "        data_with_gtrends = self.preprocess_data()\n",
    "        data_loader = None\n",
    "        if train:\n",
    "            data_loader = DataLoader(data_with_gtrends, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        else:\n",
    "            data_loader = DataLoader(data_with_gtrends, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        print('Done.')\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.data_df)\n",
    "        else:\n",
    "            return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptyArgs():\n",
    "    pass\n",
    "\n",
    "args = EmptyArgs()\n",
    "\n",
    "# General arguments\n",
    "args.log_dir='log'\n",
    "args.seed=21\n",
    "\n",
    "# Model specific arguments\n",
    "args.use_trends=1\n",
    "args.use_img=1\n",
    "args.use_text=1\n",
    "args.num_trends=3\n",
    "\n",
    "# wandb arguments\n",
    "args.wandb_entity='bonbak'\n",
    "args.wandb_proj='sflab-gtm'\n",
    "args.wandb_run='Run1'\n",
    "\n",
    "args.use_encoder_mask = False\n",
    "args.trend_len = 64  # 52\n",
    "args.prepo_data_folder = \"/home/smart01/SFLAB/sanguk/mind_br_data_prepro/\"\n",
    "args.data_folder = \"/home/smart01/SFLAB/sanguk/mind_br_data/\"\n",
    "args.text_embedder = 'klue/bert-base'\n",
    "args.sales_total_len = 12 # 52  # 12\n",
    "args.seq_len = args.sales_total_len\n",
    "args.output_dim = args.sales_total_len\n",
    "args.autoregressive = 1\n",
    "args.scaler = \"standard\" # \"Minmax\"\n",
    "args.learning_rate = 0.0001\n",
    "args.lead_time = 2\n",
    "args.no_scaling = False\n",
    "args.ahead_step = 6\n",
    "args.val_output_week = 12\n",
    "args.val_output_month = 3\n",
    "args.num_attn_heads = 8\n",
    "args.hidden_dim = 512\n",
    "args.embedding_dim = 256\n",
    "args.only_4weeks_loss = False # True\n",
    "args.num_hidden_layers = 2\n",
    "\n",
    "args.model_type = \"GTM-Classification\"\n",
    "args.autoregressive_train = False\n",
    "args.teacher_forcing = True\n",
    "args.epochs = 100 # 500  # 300  # 150  # 500 # 50 # 300  # 5  # 500  # 100 # 5  # 100\n",
    "args.batch_size = 16  # 64\n",
    "# args.gpu_num = 0\n",
    "args.before_meta = False # True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroShotDataset():\n",
    "    def __init__(self, sales_total_len, seq_len, output_dim, data_df, img_root,\n",
    "                 cat_trend, fab_trend, col_trend, trend_len,\n",
    "                 scaler, no_scaling, meta_df, qcut_df, opt_lambda=None, train=True):\n",
    "        self.sales_total_len = sales_total_len\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.data_range = self.sales_total_len - self.seq_len - self.output_dim + 1\n",
    "\n",
    "        self.data_df = data_df\n",
    "        self.img_root = img_root\n",
    "        self.cat_trend = cat_trend\n",
    "        self.fab_trend = fab_trend\n",
    "        self.col_trend = col_trend\n",
    "\n",
    "        self.img_df = meta_df.loc[:,meta_df.columns.str.startswith('img')]\n",
    "        self.text_df = meta_df.loc[:,meta_df.columns.str.startswith('text')]\n",
    "        self.meta_df = meta_df.iloc[:,3:26]\n",
    "\n",
    "        # self.text_des = text_des\n",
    "        # self.text_embedder = pipeline('feature-extraction', model=text_embedder)\n",
    "        self.trend_len = trend_len\n",
    "        self.scaler = StandardScaler() if scaler == \"standard\" else MinMaxScaler()\n",
    "        self.no_scaling = no_scaling\n",
    "\n",
    "        \n",
    "        self.qcut_df = qcut_df\n",
    "        self.qcut_label_mean = qcut_df.groupby('qcut_label')['sales_mean'].mean().values\n",
    "        self.qcut_label_median = qcut_df.groupby('qcut_label')['sales_mean'].median().values\n",
    "\n",
    "        if opt_lambda == None:\n",
    "            _, self.opt_lambda = boxcox(qcut_df.loc[self.data_df.index, 'sales_mean'])\n",
    "        else:\n",
    "            self.opt_lambda = opt_lambda\n",
    "\n",
    "        self.train = train\n",
    "        self.past_trend_len = trend_len - sales_total_len\n",
    "        self.col_imputation = self.color_imputation()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_df.iloc[idx, :]\n",
    "\n",
    "    def color_imputation(self):\n",
    "        col_trend_df = pd.DataFrame(self.col_trend)\n",
    "        normal_item_df = col_trend_df.drop(columns=[item  for item in col_trend_df.columns if col_trend_df[item][0] == \"multi_color\"])\n",
    "        col_imputation = np.mean([np.mean(normal_item_df[item]) for item in normal_item_df.columns])\n",
    "        return col_imputation\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        data = self.data_df.reset_index(drop=True)\n",
    "\n",
    "        # Get the Gtrends time series associated with each product\n",
    "        # Read the images (extracted image features) as well\n",
    "        sales, release_dates, ntrends, image_features, text_features, sales_stamps, scalers, real_value_sales, item_numbers_idx = [], [], [], [], [], [], [], [], []\n",
    "        metas = []\n",
    "        qcut_labels = []\n",
    "        target_regs = []\n",
    "\n",
    "        img_transforms = Compose([Resize((256, 256)), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "        for (idx, row) in tqdm(data.iterrows(), total=len(data), ascii=True):\n",
    "        # for (idx, row) in tqdm(data[:20].iterrows(), total=len(data[:20]), ascii=True):\n",
    "            item_numbers_idx.append(idx)\n",
    "\n",
    "            idx = self.data_df.iloc[idx]._name\n",
    "\n",
    "            meta = self.meta_df.loc[idx].values\n",
    "            metas.append(meta)\n",
    "\n",
    "            qcut = int(self.qcut_df.loc[idx]['qcut_label'])\n",
    "            qcut_labels.append(qcut)\n",
    "\n",
    "            reg = boxcox(self.qcut_df.loc[idx]['sales_mean'], self.opt_lambda)\n",
    "            target_regs.append(reg)\n",
    "\n",
    "            sales_stamp = []\n",
    "\n",
    "            row.index = pd.to_datetime(row.index)\n",
    "\n",
    "            release_date = row.dropna().sort_index().index[0]\n",
    "            release_dates.append([release_date.year, release_date.month, release_date.day])\n",
    "\n",
    "            row = row[release_date:release_date + relativedelta(weeks=self.output_dim-1)].resample('7d').sum().fillna(0)\n",
    "\n",
    "            time_feature_range = pd.date_range(release_date - relativedelta(weeks=52), release_date + relativedelta(weeks=self.output_dim-1), freq='7d')\n",
    "            sales_stamp.append(time_features(time_feature_range, freq='w')[0].tolist())\n",
    "            sales_stamp.append(time_features(time_feature_range, freq='m')[0].tolist())\n",
    "            sales_stamp.append(time_features(time_feature_range, freq='y')[0].tolist())\n",
    "\n",
    "            real_value_sale = torch.FloatTensor(np.array(row))\n",
    "            real_value_sales.append(real_value_sale)\n",
    "\n",
    "            # sale = np.array(row) / 290\n",
    "            sale = self.scaler.fit_transform(np.array(row).reshape(-1, 1)).flatten()\n",
    "\n",
    "            if self.no_scaling:\n",
    "                sale = np.array(row)\n",
    "\n",
    "            sale = torch.FloatTensor(sale)\n",
    "\n",
    "            sales.append(sale)\n",
    "\n",
    "\n",
    "            scalers.append([self.scaler.mean_, self.scaler.scale_]) if isinstance(self.scaler, StandardScaler) else scalers.append([self.scaler.data_min_, self.scaler.data_range_])\n",
    "\n",
    "            if idx in self.cat_trend.keys():\n",
    "                cat_ntrend = np.array(self.cat_trend[idx]).reshape(-1,1)\n",
    "                if cat_ntrend.shape[0] != 64:\n",
    "                    cat_ntrend = torch.zeros(self.trend_len, 1)\n",
    "\n",
    "                fab_ntrend = np.array(self.fab_trend[idx]).reshape(-1,1)\n",
    "                if fab_ntrend.shape[0] != 64:\n",
    "                    fab_ntrend = torch.zeros(self.trend_len, 1)\n",
    "\n",
    "                col_ntrend = np.array(self.col_trend[idx]).reshape(-1,1)\n",
    "                if self.col_trend[idx] == \"multi_color\":\n",
    "                    col_ntrend = torch.zeros(self.trend_len,1)\n",
    "                else:\n",
    "                    col_scaler = StandardScaler().fit(col_ntrend[:self.past_trend_len])\n",
    "                    col_ntrend = col_scaler.transform(col_ntrend)\n",
    "                if col_ntrend.shape[0] != 64:\n",
    "                    col_ntrend = torch.zeros(self.trend_len, 1)\n",
    "\n",
    "                cat_scaler = StandardScaler().fit(cat_ntrend[:self.past_trend_len])\n",
    "                cat_ntrend = cat_scaler.transform(cat_ntrend)\n",
    "                fab_scaler = StandardScaler().fit(fab_ntrend[:self.past_trend_len])\n",
    "                fab_ntrend = fab_scaler.transform(fab_ntrend)\n",
    "            else:\n",
    "                col_ntrend = torch.zeros(self.trend_len, 1)\n",
    "                cat_ntrend = torch.zeros(self.trend_len, 1)\n",
    "                fab_ntrend = torch.zeros(self.trend_len, 1)\n",
    "\n",
    "\n",
    "            \n",
    "            multitrends = torch.stack([torch.FloatTensor(cat_ntrend), torch.FloatTensor(fab_ntrend), torch.FloatTensor(col_ntrend)]).squeeze()    \n",
    "            img = Image.open(os.path.join(self.img_root, idx + '.png')).convert('RGB')\n",
    "            # textual_description = list(self.text_des.loc[idx])\n",
    "            # word_embeddings = self.text_embedder(textual_description)\n",
    "\n",
    "            # BERT gives us embeddings for [CLS] ..  [EOS], which is why we only average the embeddings in the range [1:-1]\n",
    "            # We're not fine tuning BERT and we don't want the noise coming from [CLS] or [EOS]\n",
    "            word_embeddings = torch.FloatTensor(self.text_df.loc[idx].values)\n",
    "            text_features.append(word_embeddings)\n",
    "\n",
    "            # Append them to the lists\n",
    "            ntrends.append(multitrends)\n",
    "            # img = img_transforms(self.img_df.loc[idx].values)\n",
    "            img = img_transforms(img)\n",
    "            image_features.append(img)\n",
    "\n",
    "            sales_stamp = torch.FloatTensor(sales_stamp)\n",
    "            sales_stamps.append(sales_stamp)\n",
    "\n",
    "        # Create tensors for each part of the input/output\n",
    "        item_sales = torch.stack(sales, dim=0)\n",
    "        temporal_features = torch.stack(sales_stamps, dim=0)\n",
    "        ntrends = torch.stack(ntrends, dim=0)\n",
    "        images = torch.stack(image_features, dim=0)\n",
    "        texts = torch.stack(text_features, dim=0)\n",
    "        scalers = torch.FloatTensor(np.array(scalers)).view(-1, 2)\n",
    "\n",
    "        real_value_sales = torch.stack(real_value_sales, dim=0)\n",
    "\n",
    "        release_dates = torch.tensor(release_dates)\n",
    "\n",
    "        item_numbers_idx = torch.tensor(item_numbers_idx)\n",
    "\n",
    "        meta_data = torch.FloatTensor(metas)\n",
    "        qcut_labels = torch.LongTensor(qcut_labels)\n",
    "\n",
    "        target_reg = torch.FloatTensor(target_regs)\n",
    "\n",
    "        \n",
    "        return TensorDataset(item_sales, temporal_features, ntrends, images, texts, scalers,\n",
    "                             real_value_sales, release_dates, item_numbers_idx, meta_data, \n",
    "                             qcut_labels, target_reg)\n",
    "\n",
    "    def get_loader(self, batch_size, train=True):\n",
    "        print('Starting dataset creation process...')\n",
    "        data_with_gtrends = self.preprocess_data()\n",
    "        data_loader = None\n",
    "        if train:\n",
    "            data_loader = DataLoader(data_with_gtrends, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        else:\n",
    "            data_loader = DataLoader(data_with_gtrends, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        print('Done.')\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.data_df)\n",
    "        else:\n",
    "            return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset creation process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1000/1000 [00:18<00:00, 54.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15180/719442213.py:168: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  meta_data = torch.FloatTensor(metas)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Load sales data\n",
    "df = pd.read_csv(os.path.join(args.prepo_data_folder, f\"item_sale_per_week_{args.sales_total_len}.csv\"), index_col=\"품번\")\n",
    "\n",
    "# Load Google trends\n",
    "cat_trend_per_item = pickle.load(\n",
    "    open(os.path.join(args.prepo_data_folder, \"cat_trend_per_item_v3.pkl\"), 'rb'))\n",
    "fab_trend_per_item = pickle.load(\n",
    "    open(os.path.join(args.prepo_data_folder, \"fab_trend_per_item_v3.pkl\"), 'rb'))\n",
    "col_trend_per_item = pickle.load(\n",
    "    open(os.path.join(args.prepo_data_folder, \"col_trend_per_item_v4.pkl\"), 'rb'))\n",
    "\n",
    "df = df.loc[list(set(df.index).intersection(cat_trend_per_item.keys()))]\n",
    "df = df.drop(index=['MTPT6102', 'MUPT6102'])\n",
    "\n",
    "data_path = '/home/smart01/SFLAB/su_GTM_t/GTM_T_sanguk/'\n",
    "meta_df = pd.read_csv(os.path.join(data_path, '240109_all_meta_sales_total.csv'), index_col='item_number')\n",
    "\n",
    "test_list = pickle.load(\n",
    "    open(os.path.join(data_path,\"12salesweek_test_item_number296.pkl\"), 'rb')).drop(\"MTPT6102\")[:]\n",
    "train_list = df.index[~df.index.isin(test_list)]\n",
    "train_df = df.loc[train_list]\n",
    "test_df = df.loc[test_list]\n",
    "\n",
    "qcut_df = pd.read_csv(open(os.path.join(data_path,\"qcut_df_bin10.csv\"), 'rb'), index_col='품번')\n",
    "train_qdf = qcut_df.loc[train_list]\n",
    "zero_idx = qcut_df['sales_mean']-train_qdf['sales_mean'].mean() <= train_qdf['sales_mean'].std()\n",
    "qcut_df.loc[zero_idx.values, 'qcut_label'] = 0\n",
    "qcut_df.loc[~zero_idx.values, 'qcut_label'] = 1\n",
    "\n",
    "train_dataset = ZeroShotDataset(args.sales_total_len, args.seq_len,\n",
    "                                args.output_dim, train_df,\n",
    "                                os.path.join(args.data_folder, \"images\"),\n",
    "                                cat_trend_per_item, fab_trend_per_item, col_trend_per_item,\n",
    "                                args.trend_len, args.scaler, args.no_scaling,\n",
    "                                meta_df, qcut_df, train=True)\n",
    "\n",
    "train_loader = train_dataset.get_loader(batch_size=args.batch_size, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qcut_label\n",
       "0    929\n",
       "1     71\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qcut_df.loc[train_list, 'qcut_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.2119588062211"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qcut_df.loc[qcut_df['qcut_label'] == 0, 'sales_mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qcut_label\n",
       "0    268\n",
       "1     27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qcut_df.loc[test_list, 'qcut_label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bonbak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
